[Script Info]
; Script generated by Aegisub 3.2.2
; http://www.aegisub.org/
Title: Default Aegisub file
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: TV.601
PlayResX: 1280
PlayResY: 720

[Aegisub Project Garbage]
Audio File: ../../../../视频/CRYPTO/CRYPTO 2019/The Privacy Blanket - Amplification and Summation in the Shuffle model of differential privacy.mp4
Video File: ../../../../视频/CRYPTO/CRYPTO 2019/The Privacy Blanket - Amplification and Summation in the Shuffle model of differential privacy.mp4
Video AR Mode: 4
Video AR Value: 1.777778
Video Zoom Percent: 0.625000
Scroll Position: 51
Active Line: 70
Video Position: 2173

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,微软雅黑,45,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,0,0,100,100,0,0,1,2,2,2,10,10,10,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
Dialogue: 0,0:00:00.00,0:00:05.90,Default,,0,0,0,,{\pos(639,50)}听译、时间轴：刘巍然（学酥）
Dialogue: 0,0:00:07.16,0:00:12.49,Default,,0,0,0,,我讲解的论文题目是：《隐私篮子：差分隐私置乱模型的隐私放大效应与求和方法》
Dialogue: 0,0:00:12.49,0:00:20.06,Default,,0,0,0,,在讲解我们的具体工作之前 我们需要首先介绍差分隐私和置乱模型
Dialogue: 0,0:00:21.53,0:00:28.62,Default,,0,0,0,,在差分隐私中 我们有一个数据集 数据集中包含用户的数据
Dialogue: 0,0:00:28.62,0:00:30.34,Default,,0,0,0,,我们想对数据集进行数据分析
Dialogue: 0,0:00:30.34,0:00:37.87,Default,,0,0,0,,我们希望数据分析的输出结果不过多透露出数据集中某一个个体的数据
Dialogue: 0,0:00:37.87,0:00:46.65,Default,,0,0,0,,为了形式化描述这一点 想象我们有另一个不包含我 而是包含艾蒙信息的数据集
Dialogue: 0,0:00:48.00,0:00:56.97,Default,,0,0,0,,我们不希望攻击者能通过观察输出结果 知道是我、还是艾蒙包含在数据集中
Dialogue: 0,0:00:58.53,0:01:02.48,Default,,0,0,0,,也就是说 攻击者无法区分这两个数据集的输出结果
Dialogue: 0,0:01:02.48,0:01:09.10,Default,,0,0,0,,当然了 如果在可忽略的统计距离下定义统计安全性
Dialogue: 0,0:01:09.10,0:01:11.96,Default,,0,0,0,,则根据三角不等式
Dialogue: 0,0:01:11.96,0:01:16.38,Default,,0,0,0,,即使两个数据集中所有的数据都不相同
Dialogue: 0,0:01:16.38,0:01:19.90,Default,,0,0,0,,你也不能区分两个数据集的输出结果
Dialogue: 0,0:01:19.90,0:01:22.70,Default,,0,0,0,,这意味着输出结果无法告知你任何与数据相关的有用信息
Dialogue: 0,0:01:22.70,0:01:24.23,Default,,0,0,0,,这种隐私定义也就没什么意义了
Dialogue: 0,0:01:24.23,0:01:29.48,Default,,0,0,0,,因此 我们需要定义区分两个数据集输出结果的程度 不能让不可区分性过于严苛
Dialogue: 0,0:01:30.62,0:01:35.10,Default,,0,0,0,,而这个定义就是差分隐私
Dialogue: 0,0:01:35.10,0:01:36.52,Default,,0,0,0,,差分隐私的定义是什么呢？
Dialogue: 0,0:01:36.52,0:01:41.18,Default,,0,0,0,,我们有数据集x和x' 两个数据集中只有一个数据项是不相同的
Dialogue: 0,0:01:41.18,0:01:50.59,Default,,0,0,0,,我们想讨论的是 数据分析过程给出某一输出结果的概率
Dialogue: 0,0:01:50.59,0:01:57.72,Default,,0,0,0,,大家可以把最后的δ看成是统计距离 即密码学安全常数定义下的小参数
Dialogue: 0,0:01:57.72,0:02:04.54,Default,,0,0,0,,如果认为δ=0 这个约束条件描述的是
Dialogue: 0,0:02:04.54,0:02:12.27,Default,,0,0,0,,数据集x和观察数据集x'下得到相同输出结果的似然比不超过e^ε
Dialogue: 0,0:02:12.27,0:02:19.39,Default,,0,0,0,,换句话说 攻击者无法获得、或以非常高的置信率获得过多某个个体的信息
Dialogue: 0,0:02:21.60,0:02:24.99,Default,,0,0,0,,我们如何使用这一定义呢？
Dialogue: 0,0:02:24.99,0:02:30.84,Default,,0,0,0,,最开始的时候 差分隐私是在可信模型下定义的
Dialogue: 0,0:02:30.84,0:02:35.96,Default,,0,0,0,,我们有一个可信第三方 所有人都将数据提供给这个可信第三方
Dialogue: 0,0:02:35.96,0:02:43.26,Default,,0,0,0,,可信第三方对数据进行统计 得到统计结果 并在结果上增加一些随机量
Dialogue: 0,0:02:43.26,0:02:48.11,Default,,0,0,0,,最后把结果发送给分析方 也就是发送给攻击者
Dialogue: 0,0:02:48.11,0:02:53.31,Default,,0,0,0,,我们希望分析方能从分析结果中得到一些有用的信息…
Dialogue: 0,0:02:54.22,0:03:03.82,Default,,0,0,0,,数据的分析结果是可用的 但因为M满足差分隐私 分析结果不会过多透露个体信息
Dialogue: 0,0:03:06.46,0:03:09.39,Default,,0,0,0,,随后 人们又提出了差分隐私的本地模型
Dialogue: 0,0:03:09.39,0:03:11.67,Default,,0,0,0,,此模型下 我们不再拥有可信第三方了
Dialogue: 0,0:03:11.67,0:03:15.61,Default,,0,0,0,,每个个体都在本地对自己的数据进行随机化处理
Dialogue: 0,0:03:15.61,0:03:21.15,Default,,0,0,0,,每个个体都在自己的数据上执行本地随机算法R
Dialogue: 0,0:03:21.15,0:03:25.08,Default,,0,0,0,,发送给分析方的结果数据本身就已经满足差分隐私性了
Dialogue: 0,0:03:25.08,0:03:31.69,Default,,0,0,0,,很明显 这意味着个体无法告知分析方太多与自己数据相关的信息
Dialogue: 0,0:03:31.69,0:03:35.88,Default,,0,0,0,,每一个个体传输给分析方的信息量都是有限的
Dialogue: 0,0:03:35.88,0:03:45.55,Default,,0,0,0,,但如果收集到很多用户的信息 分析方仍然可以得到与群体相关的一些信息
Dialogue: 0,0:03:47.04,0:03:48.88,Default,,0,0,0,,这里我们就需要进行权衡了
Dialogue: 0,0:03:48.88,0:03:53.64,Default,,0,0,0,,很明显 与可信模型相比 本地模型不存在过多的信任关系
Dialogue: 0,0:03:53.64,0:03:58.25,Default,,0,0,0,,但本地模型的数据分析输出结果可用性较低
Dialogue: 0,0:03:58.25,0:04:05.72,Default,,0,0,0,,在可信模型下 对[0,1]下的实数值求和 引入的随机量为O(1)
Dialogue: 0,0:04:05.72,0:04:10.19,Default,,0,0,0,,但在本地模型下 引入的随机量不可能低于O(√n)
Dialogue: 0,0:04:10.19,0:04:15.13,Default,,0,0,0,,简单来说 这是因为每个各地都需要在输入中增加O(1)的噪声
Dialogue: 0,0:04:15.13,0:04:21.44,Default,,0,0,0,,把这些噪声加在一起 噪声和的方差为O(n) 标准差为O(√n)
Dialogue: 0,0:04:24.94,0:04:29.02,Default,,0,0,0,,置乱模型位于可信模型和本地模型之间
Dialogue: 0,0:04:30.03,0:04:32.70,Default,,0,0,0,,置乱模型的基本思想是 我们有一个可信第三方
Dialogue: 0,0:04:32.70,0:04:35.92,Default,,0,0,0,,但我们只相信这个可信第三方会诚实地置乱所有的输入
Dialogue: 0,0:04:35.92,0:04:39.47,Default,,0,0,0,,可信第三方会把所有的输入放到随机置换函数中
Dialogue: 0,0:04:39.47,0:04:42.75,Default,,0,0,0,,函数把输入随机置换位置后 可信第三方再将结果发送给分析方
Dialogue: 0,0:04:45.98,0:04:48.49,Default,,0,0,0,,在实际中如何实现这一安全模型框架呢？
Dialogue: 0,0:04:48.49,0:04:52.30,Default,,0,0,0,,我们不关注这个问题 在论文中我们也没有考虑这个问题
Dialogue: 0,0:04:52.30,0:04:53.56,Default,,0,0,0,,这里有一些实现的建议
Dialogue: 0,0:04:53.56,0:04:56.84,Default,,0,0,0,,可以通过MPC实现 可以让第三方直接实现 也可以用混合网络实现
Dialogue: 0,0:04:56.84,0:05:00.36,Default,,0,0,0,,如果可以构建匿名信道 则匿名信道天生就是实现随机置乱模型的一种方法
Dialogue: 0,0:05:02.52,0:05:05.42,Default,,0,0,0,,我们论文中的实际贡献是什么呢？
Dialogue: 0,0:05:05.42,0:05:10.12,Default,,0,0,0,,到目前为止 我所介绍的都是其他学者的工作
Dialogue: 0,0:05:10.12,0:05:15.34,Default,,0,0,0,,我们考虑取值范围为[0,1]的实数值求和问题
Dialogue: 0,0:05:15.34,0:05:23.60,Default,,0,0,0,,我们证明了 单消息置乱模型的可用性比本地模型更好
Dialogue: 0,0:05:23.60,0:05:26.54,Default,,0,0,0,,但单消息置乱模型的可用性不会比可信模型更好
Dialogue: 0,0:05:26.54,0:05:31.40,Default,,0,0,0,,我们还证明了一个新的置乱隐私放大效应
Dialogue: 0,0:05:31.40,0:05:34.81,Default,,0,0,0,,我们不是第一个证明置乱隐私放大效应的学者
Dialogue: 0,0:05:34.81,0:05:40.67,Default,,0,0,0,,但我们在特定的场景下 在之前结果的基础上证明出了新的结果
Dialogue: 0,0:05:42.19,0:05:44.73,Default,,0,0,0,,来看看n个参与方下的求和问题
Dialogue: 0,0:05:44.73,0:05:49.45,Default,,0,0,0,,每个用户有一个[0,1]之间的实数 我们想计算所有实数的和
Dialogue: 0,0:05:50.36,0:05:57.68,Default,,0,0,0,,与本地模型相比 Cheu等人之前的工作在置乱模型下对协议进行了些许优化
Dialogue: 0,0:05:57.68,0:06:05.51,Default,,0,0,0,,优化协议为单消息模型 但未能证明协议的噪声标准差已达到最优
Dialogue: 0,0:06:05.51,0:06:10.17,Default,,0,0,0,,然而 他们还证明出 如果每个用户可以上传O(√n)比特长的消息
Dialogue: 0,0:06:10.17,0:06:14.81,Default,,0,0,0,,或者说每个用户向置乱方发送O(√n)次消息 置乱方对消息进行置乱处理
Dialogue: 0,0:06:14.81,0:06:18.16,Default,,0,0,0,,则协议的噪声标准差和可信模型一样
Dialogue: 0,0:06:18.16,0:06:22.57,Default,,0,0,0,,我们考虑当用户只给置乱方发送一次消息时 协议究竟能优化到何种程度
Dialogue: 0,0:06:22.57,0:06:28.86,Default,,0,0,0,,在这种情况下 我们证明了 如果用户可以只发送一次log(n)比特长的消息
Dialogue: 0,0:06:28.86,0:06:32.36,Default,,0,0,0,,则协议的噪声标准差可以达到O(n^(1/6))
Dialogue: 0,0:06:32.36,0:06:34.56,Default,,0,0,0,,即协议的噪声方差可以达到O(n^(1/3))
Dialogue: 0,0:06:34.56,0:06:39.48,Default,,0,0,0,,但这已经是最优结果了 我们不可能获得更小的噪声标准差了
Dialogue: 0,0:06:41.24,0:06:42.92,Default,,0,0,0,,我接下来将为大家证明准确性上界
Dialogue: 0,0:06:42.92,0:06:45.23,Default,,0,0,0,,因为时间关系 我不会为大家证明准确性下界
Dialogue: 0,0:06:45.23,0:06:52.11,Default,,0,0,0,,但我会解释协议的工作原理 解释如何在单消息置乱模型下得到此种准确性结果
Dialogue: 0,0:06:53.84,0:06:56.89,Default,,0,0,0,,这是本地随机算法的执行过程 算法非常简单
Dialogue: 0,0:06:58.27,0:07:00.44,Default,,0,0,0,,此算法只需要做两件事情
Dialogue: 0,0:07:00.44,0:07:04.09,Default,,0,0,0,,当获得真实输入后 我们将其转换为固定精度下的值
Dialogue: 0,0:07:04.09,0:07:11.82,Default,,0,0,0,,也就是说 我们在k固定精度下对输入进行随机舍入处理
Dialogue: 0,0:07:11.82,0:07:17.24,Default,,0,0,0,,随后 我们将执行k元随机答复协议
Dialogue: 0,0:07:17.24,0:07:22.25,Default,,0,0,0,,也就是说 每个用户随机抛掷一枚有偏的硬币
Dialogue: 0,0:07:22.25,0:07:29.42,Default,,0,0,0,,每个用户有γ的概率返回一个与输入独立、满足均匀随机分布的答复结果
Dialogue: 0,0:07:29.42,0:07:33.50,Default,,0,0,0,,每个用户有1-γ的概率答复真实结果
Dialogue: 0,0:07:34.75,0:07:38.54,Default,,0,0,0,,最后 分析方将调用deBias算法 使统计结果满足无偏性
Dialogue: 0,0:07:38.54,0:07:41.44,Default,,0,0,0,,这一步处理过程非常简单 只需要执行一次线性映射
Dialogue: 0,0:07:42.49,0:07:44.59,Default,,0,0,0,,这就是本地随机算法的执行过程
Dialogue: 0,0:07:44.59,0:07:47.52,Default,,0,0,0,,为什么此算法可以实现我们给出的准确性要求呢？
Dialogue: 0,0:07:48.46,0:07:50.28,Default,,0,0,0,,此算法包含两个噪声源
Dialogue: 0,0:07:50.28,0:07:54.92,Default,,0,0,0,,第一个噪声源是将输入随机舍入到固定精度时引入的噪声
Dialogue: 0,0:07:54.92,0:07:59.37,Default,,0,0,0,,此噪声的方差是O(n/k^2)
Dialogue: 0,0:07:59.37,0:08:00.60,Default,,0,0,0,,因为有n个参与方 所以有O(n)的噪声
Dialogue: 0,0:08:00.60,0:08:04.65,Default,,0,0,0,,而随机舍入又会引入方差为O(1/k^2)的噪声
Dialogue: 0,0:08:04.65,0:08:15.02,Default,,0,0,0,,第二个噪声源是一部分用户会给出与输入完全独立、满足均匀随机分布的答复结果
Dialogue: 0,0:08:15.84,0:08:21.14,Default,,0,0,0,,一共有大约O(γn)用户会给出错误的答复
Dialogue: 0,0:08:21.14,0:08:24.00,Default,,0,0,0,,每个用户错误答复所引入的噪声量为O(1)
Dialogue: 0,0:08:24.00,0:08:26.94,Default,,0,0,0,,因此这部分噪声源将引入方差为O(γn)的噪声
Dialogue: 0,0:08:26.94,0:08:29.42,Default,,0,0,0,,在接下来的几分钟我会为大家证明
Dialogue: 0,0:08:29.42,0:08:36.84,Default,,0,0,0,,我们需要将γ设置为k/n乘以一个与δ和ε相关的函数
Dialogue: 0,0:08:36.84,0:08:44.33,Default,,0,0,0,,如果把系数k/n带入到最上方的噪声量中 我们就会得到噪声方差为O(n/k^2)+O(k)
Dialogue: 0,0:08:44.33,0:08:47.36,Default,,0,0,0,,因此 我们希望k大致等于O(n^(1/3))即可
Dialogue: 0,0:08:47.36,0:08:51.40,Default,,0,0,0,,如果令k等于O(n^(1/3)) 则噪声方差将变为O(n^(1/3))
Dialogue: 0,0:08:51.40,0:08:53.77,Default,,0,0,0,,因此 噪声标准差为O(n^(1/6))
Dialogue: 0,0:08:53.77,0:08:56.60,Default,,0,0,0,,这就是协议噪声标准差为O(n^(1/6))的原因
Dialogue: 0,0:08:57.96,0:09:01.87,Default,,0,0,0,,为什么我们要让γ等于这个值呢？为什么这么设置就够了呢？
Dialogue: 0,0:09:03.88,0:09:07.77,Default,,0,0,0,,为了证明这一点 我们需要考察攻击者在此模型下可以得到哪些信息
Dialogue: 0,0:09:07.77,0:09:09.93,Default,,0,0,0,,这是攻击者的视角
Dialogue: 0,0:09:10.88,0:09:12.76,Default,,0,0,0,,攻击者能得到信息可以等价为一张直方图
Dialogue: 0,0:09:12.76,0:09:17.93,Default,,0,0,0,,攻击者只能知道每一个输入值、或者说每一个原始值被上传了多少次
Dialogue: 0,0:09:17.93,0:09:21.39,Default,,0,0,0,,因此攻击者得到的是所有输入值的一张直方图
Dialogue: 0,0:09:22.54,0:09:28.88,Default,,0,0,0,,而攻击者知道 在得到这张直方图的过程中 有的用户在说谎 有的用户在说实话
Dialogue: 0,0:09:28.88,0:09:33.45,Default,,0,0,0,,我们把给出随机答复的用户所形成的直方图看作绿色直方图
Dialogue: 0,0:09:33.45,0:09:36.00,Default,,0,0,0,,把给出真实答复的用户所形成的直方图看作红色直方图
Dialogue: 0,0:09:36.00,0:09:38.35,Default,,0,0,0,,攻击者明显不知道直方图中哪一部分是红色的、哪一部分是绿色的
Dialogue: 0,0:09:39.08,0:09:41.48,Default,,0,0,0,,但我们要告诉攻击者直方图中哪一部分是红色的、哪一部分是绿色的
Dialogue: 0,0:09:42.89,0:09:49.24,Default,,0,0,0,,我们要给攻击者一个礼物 告诉攻击者哪些用户给出的是真实答复
Dialogue: 0,0:09:49.24,0:09:55.08,Default,,0,0,0,,我们还假设攻击者知道除目标用户之外 所有用户的真实输入
Dialogue: 0,0:09:56.09,0:09:59.15,Default,,0,0,0,,这是差分隐私中的一个标准假设
Dialogue: 0,0:09:59.15,0:10:02.20,Default,,0,0,0,,我们希望攻击者在足够多的背景知识下 仍然无法得到某个个体的信息
Dialogue: 0,0:10:03.24,0:10:09.55,Default,,0,0,0,,有了这个礼物 攻击者可以从直方图中移除答复真实结果的用户
Dialogue: 0,0:10:09.55,0:10:15.13,Default,,0,0,0,,如果目标用户给出的是真实答复 留给攻击者的就是绿色的直方图加上他的数据项
Dialogue: 0,0:10:15.13,0:10:20.64,Default,,0,0,0,,如果目标用户在撒谎 他的答复就与真实数据相互独立 结果中不会泄露任何信息
Dialogue: 0,0:10:20.64,0:10:24.14,Default,,0,0,0,,因此 我们只需要担心当目标用户给出真实答复下的情况
Dialogue: 0,0:10:26.24,0:10:32.67,Default,,0,0,0,,我们把绿色直方图称为隐私篮子
Dialogue: 0,0:10:32.67,0:10:36.97,Default,,0,0,0,,隐私篮子的基本思想是 目标用户的数据可以被其他用户的独立随机数据所覆盖
Dialogue: 0,0:10:36.97,0:10:40.51,Default,,0,0,0,,隐私篮子可以盖住目标用户的真实数据
Dialogue: 0,0:10:43.26,0:10:48.03,Default,,0,0,0,,攻击者需要有能力区分两种场景下的答复结果
Dialogue: 0,0:10:48.03,0:10:57.36,Default,,0,0,0,,他需要告诉我们 答复结果是额外增加一个0得到的 还是额外增加一个1得到的
Dialogue: 0,0:10:59.37,0:11:02.47,Default,,0,0,0,,我们需要考察两个概率分布的似然比
Dialogue: 0,0:11:02.47,0:11:08.30,Default,,0,0,0,,正如我前面所提到的 差分隐私要求似然比不能大于e^ε
Dialogue: 0,0:11:08.30,0:11:14.81,Default,,0,0,0,,因此 我们只需要证明这两个直方图出现的似然比大于e^ε的概率最大为δ
Dialogue: 0,0:11:17.08,0:11:22.11,Default,,0,0,0,,为了证明这一点 我们需要计算似然比
Dialogue: 0,0:11:23.82,0:11:36.25,Default,,0,0,0,,当你的答复是0时 似然比就等于0提交的个数除以1提交的个数
Dialogue: 0,0:11:36.25,0:11:41.93,Default,,0,0,0,,即似然比等于某个二项随机变量加1除以某个二项随机变量
Dialogue: 0,0:11:41.93,0:11:46.01,Default,,0,0,0,,我们要求两个随机变量的比值不大于e^ε
Dialogue: 0,0:11:46.01,0:11:50.59,Default,,0,0,0,,因为二项随机变量分布很集中于概率分布均值
Dialogue: 0,0:11:50.59,0:11:54.16,Default,,0,0,0,,因此只要均值足够大 两个随机变量的比值就不会大于e^ε
Dialogue: 0,0:11:54.16,0:11:56.67,Default,,0,0,0,,均值应该为多大呢？
Dialogue: 0,0:11:56.67,0:12:00.83,Default,,0,0,0,,均值应该等于ε和δ下的某个函数
Dialogue: 0,0:12:01.61,0:12:12.72,Default,,0,0,0,,如果想让均值等于某个常数 则可令γ等于k/n乘以某个ε和δ下的函数
Dialogue: 0,0:12:12.72,0:12:18.43,Default,,0,0,0,,如果你对差分隐私很熟悉 你可能就会对log(1/δ)/ε^2这个参数很熟悉
Dialogue: 0,0:12:18.43,0:12:26.52,Default,,0,0,0,,这是在差分隐私中使用高斯机制时 所需要增加的噪声方差
Dialogue: 0,0:12:26.52,0:12:33.12,Default,,0,0,0,,这个结果应该并不令人惊讶 因为隐藏信息用的二项随机变量近似等于高斯随机变量
Dialogue: 0,0:12:33.12,0:12:36.09,Default,,0,0,0,,这就是为什么会出现log(1/δ)/ε^2的原因
Dialogue: 0,0:12:37.06,0:12:40.41,Default,,0,0,0,,这就是隐私性证明过程了
Dialogue: 0,0:12:41.40,0:12:43.88,Default,,0,0,0,,我们再来看看隐私放大效应
Dialogue: 0,0:12:44.78,0:12:48.57,Default,,0,0,0,,我在前面已经证明我们可以用此协议实现实数求和
Dialogue: 0,0:12:48.57,0:12:58.78,Default,,0,0,0,,这里的问题是 我们是否可以把相应的结论扩展到其它统计函数上？
Dialogue: 0,0:12:58.78,0:13:07.28,Default,,0,0,0,,Erlingsson等人最近证明出 如果你有一个满足一定条件的本地随机算法…
Dialogue: 0,0:13:07.28,0:13:14.59,Default,,0,0,0,,假定本地模型下的差分隐私参数为ε_0 其中ε_0为一个常数
Dialogue: 0,0:13:15.68,0:13:21.18,Default,,0,0,0,,你就可以自动在置乱模型下满足差分隐私性 且对应的参数更优
Dialogue: 0,0:13:21.18,0:13:28.83,Default,,0,0,0,,你需要引入一个非0参数δ 但参数ε_0下会除以一个√n
Dialogue: 0,0:13:28.83,0:13:32.73,Default,,0,0,0,,也就是说 如果n很大 则ε会降低很多
Dialogue: 0,0:13:33.76,0:13:35.61,Default,,0,0,0,,这是一个很有用的结论
Dialogue: 0,0:13:36.36,0:13:41.29,Default,,0,0,0,,虽然我们希望获得较好的隐私性保证 但在很多场景下 我们不希望太好的隐私性保证
Dialogue: 0,0:13:41.29,0:13:45.68,Default,,0,0,0,,我们希望的是合理隐私性保证和高可用性
Dialogue: 0,0:13:45.68,0:13:55.68,Default,,0,0,0,,我们扩展了Erlingsson的结论 可以让本地模型下的ε_0设置得更大
Dialogue: 0,0:13:55.68,0:13:59.71,Default,,0,0,0,,大家可以观察右侧的等式 ε的表达式中包含了一个e^ε_0
Dialogue: 0,0:13:59.71,0:14:05.56,Default,,0,0,0,,这个参数会随着ε_0的增大而快速增大
Dialogue: 0,0:14:05.56,0:14:14.57,Default,,0,0,0,,这里的关键点是 你可以令ε_0等于O(log(n)) 但仍然能获得ε=1的差分隐私性保证
Dialogue: 0,0:14:16.66,0:14:25.23,Default,,0,0,0,,实际上 即使我们令ε_0=1/2 令δ=10^(-6)
Dialogue: 0,0:14:25.23,0:14:31.82,Default,,0,0,0,,这个图也告诉我们 我们结果中的隐私放大效应常数要比Erlingsson等人的结果更好
Dialogue: 0,0:14:33.80,0:14:37.90,Default,,0,0,0,,这是因为我们的攻击方法比他们的攻击方法更加直接
Dialogue: 0,0:14:38.75,0:14:45.77,Default,,0,0,0,,我必须要说明的是 从系统和应用层面看 他们的结论要比我们的结论更通用
Dialogue: 0,0:14:45.77,0:14:52.04,Default,,0,0,0,,他们的模型和我们的模型有所不同
Dialogue: 0,0:14:52.04,0:14:54.32,Default,,0,0,0,,因此 不能说我们得到了更强的结果
Dialogue: 0,0:14:56.43,0:15:00.44,Default,,0,0,0,,你可能会问一个问题 如果我们应用置乱隐私放大效应
Dialogue: 0,0:15:00.44,0:15:08.41,Default,,0,0,0,,是不是意味着我们可以寻找一个可以在本地模型下实现差分隐私的本地随机算法
Dialogue: 0,0:15:08.41,0:15:11.20,Default,,0,0,0,,然后直接在这上面应用置乱隐私放大效应？
Dialogue: 0,0:15:12.48,0:15:15.24,Default,,0,0,0,,可以说对 也可以说不对
Dialogue: 0,0:15:15.24,0:15:21.52,Default,,0,0,0,,如果在本地模型下应用我这里给大家介绍的置乱模型下的随机算法
Dialogue: 0,0:15:21.52,0:15:30.90,Default,,0,0,0,,则当随机算法的ε参数设置得很大 例如设置为O(log(n))时
Dialogue: 0,0:15:30.90,0:15:37.80,Default,,0,0,0,,直接应用置乱隐私放大效应 就可以得到我前面给出的隐私放大效应结果了
Dialogue: 0,0:15:41.25,0:15:47.12,Default,,0,0,0,,然而 如果你随便选择了一个本地模型下的本地随机算法
Dialogue: 0,0:15:47.12,0:15:50.19,Default,,0,0,0,,例如随便一个输入范围是[0,1]的随机算法
Dialogue: 0,0:15:50.19,0:15:54.09,Default,,0,0,0,,比如简单随机答复 或者直接在结果上增加Laplace噪声
Dialogue: 0,0:15:54.09,0:15:56.99,Default,,0,0,0,,则置乱隐私放大效应的结果并不会太理想
Dialogue: 0,0:15:56.99,0:16:01.88,Default,,0,0,0,,隐私放大效应的系数可能只能到√n 甚至只能到log(n)
Dialogue: 0,0:16:01.88,0:16:07.96,Default,,0,0,0,,因此 你需要适当选择本地随机算法 使其在置乱模型下可以得到最优的准确性
Dialogue: 0,0:16:07.96,0:16:14.45,Default,,0,0,0,,而不是选择一个在本地模型下最优的本地随机算法 再直接应用置乱隐私放大效应
Dialogue: 0,0:16:16.30,0:16:17.29,Default,,0,0,0,,不好意思 点错了
Dialogue: 0,0:16:19.85,0:16:21.66,Default,,0,0,0,,这里还有另一个问题
Dialogue: 0,0:16:21.66,0:16:26.76,Default,,0,0,0,,我之前提到 我们的协议是在单消息模型下构建的 多消息模型下会得到什么结果呢？
Dialogue: 0,0:16:27.29,0:16:31.84,Default,,0,0,0,,Chou等人证明 如果发送O(√n)个单比特消息 就可以进一步提高准确性
Dialogue: 0,0:16:31.84,0:16:34.80,Default,,0,0,0,,置乱模型下的准确性结果可以和可信模型几乎完全相同
Dialogue: 0,0:16:36.64,0:16:41.96,Default,,0,0,0,,{\pos(650,100)}@注释：论文题目为《Differentially Private Summation with Multi-Message Shuffling》
Dialogue: 0,0:16:36.64,0:16:41.96,Default,,0,0,0,,在提交此论文后 我们最近在Arxiv上在线提交了一个笔记
Dialogue: 0,0:16:41.96,0:16:45.15,Default,,0,0,0,,答案是一样的 的确可以做得更好
Dialogue: 0,0:16:45.15,0:16:48.56,Default,,0,0,0,,那篇笔记并没有涉及太多新的研究成果
Dialogue: 0,0:16:48.56,0:16:56.12,Default,,0,0,0,,我们证明 可以让通信量降低到O(log(n)) 但是每个消息的长度也为O(log(n))
Dialogue: 0,0:16:56.12,0:17:01.71,Default,,0,0,0,,即发送O(log(n))个O(log(n))比特长的消息 而不是发送O(√n)个单比特长的消息
Dialogue: 0,0:17:01.71,0:17:04.46,Default,,0,0,0,,如何做到的呢？
Dialogue: 0,0:17:06.75,0:17:12.48,Default,,0,0,0,,协议的基本思想可以追溯到Ishai等人在2006年发表的论文
Dialogue: 0,0:17:12.48,0:17:22.20,Default,,0,0,0,,那篇论文称 如果你有一个匿名通信信道 你就可以在统计安全下实现安全求和功能
Dialogue: 0,0:17:23.68,0:17:30.92,Default,,0,0,0,,我们可以在输入上加入随机噪声 每个参与方都可以在输入上加入随机噪声
Dialogue: 0,0:17:30.92,0:17:41.23,Default,,0,0,0,,随后 应用Ishai等人的协议 通过发送O(log(n))个消息实现隐私求和
Dialogue: 0,0:17:42.62,0:17:53.55,Default,,0,0,0,,如果你可以接受发送O(log(n))次消息 你就可以得到与可信模型相同的准确性结果
Dialogue: 0,0:17:53.55,0:17:56.00,Default,,0,0,0,,还剩下哪些公开问题呢？
Dialogue: 0,0:17:59.76,0:18:04.00,Default,,0,0,0,,我前面讲到 发送O(log(n))个消息足以得到与可信模型相同的准确性结果
Dialogue: 0,0:18:04.00,0:18:06.14,Default,,0,0,0,,单消息模型做不到那么高的准确性
Dialogue: 0,0:18:06.14,0:18:10.44,Default,,0,0,0,,你可能会问 如果是双消息呢？三消息呢？log(log(n))消息呢？
Dialogue: 0,0:18:10.44,0:18:15.76,Default,,0,0,0,,我们正在考虑这个问题 但到目前为止我们还不确定结果是什么
Dialogue: 0,0:18:19.53,0:18:23.20,Default,,0,0,0,,我们还应该考察除求和以外的其它统计方法
Dialogue: 0,0:18:23.20,0:18:29.26,Default,,0,0,0,,这个模型的基本思想是 只要我们有一个置乱、或者说匿名通信信道
Dialogue: 0,0:18:29.26,0:18:32.96,Default,,0,0,0,,我们就可以利用这个信道计算得到很多统计结果
Dialogue: 0,0:18:32.96,0:18:35.69,Default,,0,0,0,,只需要一次性实现这个匿名通信信道
Dialogue: 0,0:18:35.69,0:18:39.56,Default,,0,0,0,,我们就可以非常高效地计算很多不同的统计结果
Dialogue: 0,0:18:39.56,0:18:44.35,Default,,0,0,0,,只有当可以利用这个模型计算很多不同的统计结果时 我们才能说这个模型是有用的
Dialogue: 0,0:18:44.35,0:18:51.12,Default,,0,0,0,,因此 如果想说明这个模型是有用的 我们需要在此模型下构建其它统计计算方法
Dialogue: 0,0:18:52.25,0:18:54.94,Default,,0,0,0,,我们还需要解释如何实现置乱模型
Dialogue: 0,0:18:54.94,0:19:00.24,Default,,0,0,0,,已经有相关的学者尝试在可信硬件下实现置乱模型了
Dialogue: 0,0:19:00.24,0:19:05.61,Default,,0,0,0,,在差分隐私置乱模型出现之前 就已经出现了相关的工作
Dialogue: 0,0:19:05.61,0:19:13.31,Default,,0,0,0,,原因是 直观上看 在查看数据之前先置乱数据应该可以提高隐私性
Dialogue: 0,0:19:17.87,0:19:23.15,Default,,0,0,0,,我们或许可以使用MPC、混合网络、或者通过其它方法实现置乱模型
Dialogue: 0,0:19:23.15,0:19:30.09,Default,,0,0,0,,我们需查看不同的实现方法 寻找最容易、最轻量级的实现方法来构建置乱模型
Dialogue: 0,0:19:33.00,0:19:35.71,Default,,0,0,0,,另一个问题是 置乱模型包含了一个可信假设
Dialogue: 0,0:19:36.12,0:19:42.60,Default,,0,0,0,,在证明过程中 大家可能已经注意到 我假设每个用户都会严格遵循协议要求执行协议
Dialogue: 0,0:19:42.60,0:19:45.88,Default,,0,0,0,,我们不需要假设每个用户都严格按照要求执行协议
Dialogue: 0,0:19:45.88,0:19:51.45,Default,,0,0,0,,只要有一定比例的用户会按照要求执行协议 这个协议就能保证隐私性
Dialogue: 0,0:19:51.45,0:19:55.24,Default,,0,0,0,,但我们需要让足够多的用户按照要求执行协议
Dialogue: 0,0:19:55.24,0:20:03.58,Default,,0,0,0,,只要足够多的用户随机答复 攻击者就无法知道目标用户的回复结果是什么了
Dialogue: 0,0:20:03.58,0:20:07.48,Default,,0,0,0,,因此 这些用户的安全假设并非是半可信的 他们必须是可信的
Dialogue: 0,0:20:07.48,0:20:11.48,Default,,0,0,0,,这样我们才能得到足够大的隐私篮子 从而隐藏目标用户的回复结果
Dialogue: 0,0:20:11.48,0:20:23.96,Default,,0,0,0,,你可能会想到 或许基于MPC的置乱协议可以帮助验证噪声是否已经正确添加
Dialogue: 0,0:20:23.96,0:20:29.82,Default,,0,0,0,,噪声添加过程、或者随机答复过程也可以在MPC中进行 以保证噪声被正确添加
Dialogue: 0,0:20:29.82,0:20:34.76,Default,,0,0,0,,这样就可以让这些用户的安全假设从可信退化到半可信
Dialogue: 0,0:20:36.22,0:20:44.84,Default,,0,0,0,,如果上述问题都能实现 假设就都可以成立 整个系统就满足置乱模型了
Dialogue: 0,0:20:44.84,0:20:47.68,Default,,0,0,0,,如果我们能移除可信假设 协议会变得更好
Dialogue: 0,0:20:48.56,0:20:50.94,Default,,0,0,0,,不过 置乱模型可能也不是最优的
Dialogue: 0,0:20:50.94,0:20:55.45,Default,,0,0,0,,可能可以有更好、更容易实现的模型 可以支持更多的统计计算
Dialogue: 0,0:20:55.45,0:21:03.12,Default,,0,0,0,,因此 另一个问题是 是否还存在其它的模型 可以进一步优化统计计算的准确性？
Dialogue: 0,0:21:04.14,0:21:06.83,Default,,0,0,0,,这就是我的讲座内容 谢谢大家
Dialogue: 0,0:21:13.10,0:21:16.19,Default,,0,0,0,,感谢James的精彩讲座 大家有什么问题吗？
Dialogue: 0,0:21:20.73,0:21:26.43,Default,,0,0,0,,如果没有其它问题 那就让我们再次感谢James 以及感谢本分会场所有的演讲者
Dialogue: 0,0:21:21.43,0:21:26.43,Default,,0,0,0,,{\pos(639,50)}听译、时间轴：刘巍然（学酥）
